{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c946050",
   "metadata": {},
   "source": [
    "Dieses Skript trainiert zunächst den ersten Random Forest ohne weitere Einstellungen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5389e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features and labels for sessions: 100%|██████████| 268/268 [00:05<00:00, 49.93it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of 100 | elapsed:  1.0min remaining:  9.2min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.6min finished\n",
      "Extracting features and labels for sessions: 100%|██████████| 268/268 [00:01<00:00, 166.93it/s]\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    1.4s remaining:   13.0s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    2.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "Kein Artefakt       0.91      0.92      0.91    971776\n",
      "     Artefakt       0.61      0.56      0.58    210350\n",
      "\n",
      "     accuracy                           0.86   1182126\n",
      "    macro avg       0.76      0.74      0.75   1182126\n",
      " weighted avg       0.85      0.86      0.86   1182126\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from utils.training import train_random_forest, predict_random_forest\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "feature_file = \"./features/features.hdf5\"\n",
    "data_split_file = \"./data_split.yaml\"\n",
    "features = ['mean', 'variance', 'std', 'ptp_amp', 'skewness', 'kurtosis', 'quantile']\n",
    "model_save_path = f'./models/{datetime.now().strftime('%d-%m-%y %H-%M-%S')}.joblib'\n",
    "random_state = 42\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=-1, verbose=1, random_state=random_state)\n",
    "\n",
    "clf = train_random_forest(clf, feature_file, features, data_split_file)\n",
    "y_true, y_pred = predict_random_forest(clf, feature_file, features, data_split_file)\n",
    "joblib.dump(clf, model_save_path)\n",
    "print(classification_report(y_true, y_pred, target_names=[\"Kein Artefakt\", \"Artefakt\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1244d4",
   "metadata": {},
   "source": [
    "Das Experiment hat funktioniert. Wie gut die Ergebnisse wirklich sind, bin ich mir noch nicht sicher. Allerdings wurden auch nur grundlegende features verwendet. Die Artefakte wurden nur  zu ca. 56% richtig erkannt. Im Folgenden werde ich ein weiteres Modell trainieren, dass auf allen Features basiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986885b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features and labels for sessions: 100%|██████████| 268/268 [00:09<00:00, 28.26it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of 100 | elapsed:  1.3min remaining: 12.1min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.1min finished\n",
      "Extracting features and labels for sessions: 100%|██████████| 268/268 [00:02<00:00, 103.88it/s]\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    1.0s remaining:    9.4s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "Kein Artefakt       0.91      0.92      0.92    971776\n",
      "     Artefakt       0.62      0.58      0.60    210350\n",
      "\n",
      "     accuracy                           0.86   1182126\n",
      "    macro avg       0.76      0.75      0.76   1182126\n",
      " weighted avg       0.86      0.86      0.86   1182126\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from utils.training import train_random_forest, predict_random_forest\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "feature_file = \"./features/features.hdf5\"\n",
    "data_split_file = \"./data_split.yaml\"\n",
    "features = ['mean', 'variance', 'std', 'ptp_amp', 'skewness', 'kurtosis', 'quantile', 'pow_freq_bands', 'hurst_exp', 'decorr_time']\n",
    "model_save_path = f'./models/{datetime.now().strftime('%d-%m-%y %H-%M-%S')}.joblib'\n",
    "random_state = 42\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=-1, verbose=1, random_state=random_state)\n",
    "\n",
    "clf = train_random_forest(clf, feature_file, features, data_split_file)\n",
    "y_true, y_pred = predict_random_forest(clf, feature_file, features, data_split_file)\n",
    "joblib.dump(clf, model_save_path)\n",
    "print(classification_report(y_true, y_pred, target_names=[\"Kein Artefakt\", \"Artefakt\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960a45f9",
   "metadata": {},
   "source": [
    "Die Ergebnisse haben sich nochmal verbessert. Im Folgenden werde ich die Auswirkung von mehr Bäumen untersuchen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4056cfeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features and labels for sessions: 100%|██████████| 268/268 [00:09<00:00, 27.86it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 258 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  7.5min finished\n",
      "Extracting features and labels for sessions: 100%|██████████| 268/268 [00:02<00:00, 107.28it/s]\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done   8 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=96)]: Done 258 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=96)]: Done 500 out of 500 | elapsed:    6.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "Kein Artefakt       0.91      0.92      0.92    971776\n",
      "     Artefakt       0.62      0.58      0.60    210350\n",
      "\n",
      "     accuracy                           0.86   1182126\n",
      "    macro avg       0.77      0.75      0.76   1182126\n",
      " weighted avg       0.86      0.86      0.86   1182126\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from utils.training import train_random_forest, predict_random_forest\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "feature_file = \"./features/features.hdf5\"\n",
    "data_split_file = \"./data_split.yaml\"\n",
    "features = ['mean', 'variance', 'std', 'ptp_amp', 'skewness', 'kurtosis', 'quantile', 'pow_freq_bands', 'hurst_exp', 'decorr_time']\n",
    "model_save_path = f'./models/{datetime.now().strftime('%d-%m-%y %H-%M-%S')}.joblib'\n",
    "random_state = 42\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=500, n_jobs=-1, verbose=1, random_state=random_state)\n",
    "\n",
    "clf = train_random_forest(clf, feature_file, features, data_split_file)\n",
    "y_true, y_pred = predict_random_forest(clf, feature_file, features, data_split_file)\n",
    "joblib.dump(clf, model_save_path)\n",
    "print(classification_report(y_true, y_pred, target_names=[\"Kein Artefakt\", \"Artefakt\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b5c31b",
   "metadata": {},
   "source": [
    "Die Ergebnisse haben sich kaum, bzw. fast gar nicht verbessert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75704302",
   "metadata": {},
   "source": [
    "Im Folgenden werden auch hier wieder die Ergebnisse der Daten ohne Hochpass erzeugt, um sie dann zu vergleichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e1ed1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features and labels for sessions: 100%|██████████| 268/268 [00:05<00:00, 48.20it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of 100 | elapsed:   57.7s remaining:  8.7min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.5min finished\n",
      "Extracting features and labels for sessions: 100%|██████████| 268/268 [00:01<00:00, 170.44it/s]\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    1.3s remaining:   12.0s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "Kein Artefakt       0.91      0.92      0.91    971776\n",
      "     Artefakt       0.61      0.56      0.58    210350\n",
      "\n",
      "     accuracy                           0.86   1182126\n",
      "    macro avg       0.76      0.74      0.75   1182126\n",
      " weighted avg       0.85      0.86      0.86   1182126\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from utils.training import train_random_forest, predict_random_forest\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "feature_file = \"./features/features_no_hp.hdf5\"\n",
    "data_split_file = \"./data_split.yaml\"\n",
    "features = ['mean', 'variance', 'std', 'ptp_amp', 'skewness', 'kurtosis', 'quantile']\n",
    "model_save_path = f'./models/{datetime.now().strftime('%d-%m-%y %H-%M-%S')}.joblib'\n",
    "random_state = 42\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=-1, verbose=1, random_state=random_state)\n",
    "\n",
    "clf = train_random_forest(clf, feature_file, features, data_split_file)\n",
    "y_true, y_pred = predict_random_forest(clf, feature_file, features, data_split_file)\n",
    "joblib.dump(clf, model_save_path)\n",
    "print(classification_report(y_true, y_pred, target_names=[\"Kein Artefakt\", \"Artefakt\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414c5d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features and labels for sessions: 100%|██████████| 268/268 [00:07<00:00, 36.64it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of 100 | elapsed:  1.3min remaining: 11.3min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.0min finished\n",
      "Extracting features and labels for sessions: 100%|██████████| 268/268 [00:02<00:00, 125.93it/s]\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    1.0s remaining:    9.2s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "Kein Artefakt       0.91      0.92      0.92    971776\n",
      "     Artefakt       0.62      0.58      0.60    210350\n",
      "\n",
      "     accuracy                           0.86   1182126\n",
      "    macro avg       0.76      0.75      0.76   1182126\n",
      " weighted avg       0.86      0.86      0.86   1182126\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from utils.training import train_random_forest, predict_random_forest\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "feature_file = \"./features/features_no_hp.hdf5\"\n",
    "data_split_file = \"./data_split.yaml\"\n",
    "features = ['mean', 'variance', 'std', 'ptp_amp', 'skewness', 'kurtosis', 'quantile', 'pow_freq_bands', 'hurst_exp', 'decorr_time']\n",
    "model_save_path = f'./models/{datetime.now().strftime('%d-%m-%y %H-%M-%S')}.joblib'\n",
    "random_state = 42\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=-1, verbose=1, random_state=random_state)\n",
    "\n",
    "clf = train_random_forest(clf, feature_file, features, data_split_file)\n",
    "y_true, y_pred = predict_random_forest(clf, feature_file, features, data_split_file)\n",
    "joblib.dump(clf, model_save_path)\n",
    "print(classification_report(y_true, y_pred, target_names=[\"Kein Artefakt\", \"Artefakt\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a155b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features and labels for sessions: 100%|██████████| 268/268 [00:07<00:00, 36.57it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 258 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  7.0min finished\n",
      "Extracting features and labels for sessions: 100%|██████████| 268/268 [00:02<00:00, 126.53it/s]\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done   8 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=96)]: Done 258 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=96)]: Done 500 out of 500 | elapsed:    6.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "Kein Artefakt       0.91      0.92      0.92    971776\n",
      "     Artefakt       0.62      0.58      0.60    210350\n",
      "\n",
      "     accuracy                           0.86   1182126\n",
      "    macro avg       0.76      0.75      0.76   1182126\n",
      " weighted avg       0.86      0.86      0.86   1182126\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from utils.training import train_random_forest, predict_random_forest\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "feature_file = \"./features/features_no_hp.hdf5\"\n",
    "data_split_file = \"./data_split.yaml\"\n",
    "features = ['mean', 'variance', 'std', 'ptp_amp', 'skewness', 'kurtosis', 'quantile', 'pow_freq_bands', 'hurst_exp', 'decorr_time']\n",
    "model_save_path = f'./models/{datetime.now().strftime('%d-%m-%y %H-%M-%S')}.joblib'\n",
    "random_state = 42\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=500, n_jobs=-1, verbose=1, random_state=random_state)\n",
    "\n",
    "clf = train_random_forest(clf, feature_file, features, data_split_file)\n",
    "y_true, y_pred = predict_random_forest(clf, feature_file, features, data_split_file)\n",
    "joblib.dump(clf, model_save_path)\n",
    "print(classification_report(y_true, y_pred, target_names=[\"Kein Artefakt\", \"Artefakt\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816ca34e",
   "metadata": {},
   "source": [
    "Im Folgenden wird nun wieder mit den Daten mit Hochpass trainiert. Dabei wird nun jedoch die Class Imbalance beim Trainieren des RandomForrest behandelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed362ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features and labels for sessions:   0%|          | 0/268 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features and labels for sessions: 100%|██████████| 268/268 [00:07<00:00, 36.84it/s]\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    3.6s remaining:   32.1s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    5.5s finished\n",
      "Extracting features and labels for sessions: 100%|██████████| 268/268 [00:02<00:00, 121.52it/s]\n",
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=96)]: Done  10 out of 100 | elapsed:    1.0s remaining:    8.7s\n",
      "[Parallel(n_jobs=96)]: Done 100 out of 100 | elapsed:    1.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifiction report training set \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Kein Artefakt       1.00      1.00      1.00   3367153\n",
      "     Artefakt       1.00      1.00      1.00    811909\n",
      "\n",
      "     accuracy                           1.00   4179062\n",
      "    macro avg       1.00      1.00      1.00   4179062\n",
      " weighted avg       1.00      1.00      1.00   4179062\n",
      "\n",
      "\n",
      "\n",
      "Classifiction report validtation set \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Kein Artefakt       0.91      0.93      0.92    971776\n",
      "     Artefakt       0.63      0.55      0.59    210350\n",
      "\n",
      "     accuracy                           0.86   1182126\n",
      "    macro avg       0.77      0.74      0.75   1182126\n",
      " weighted avg       0.86      0.86      0.86   1182126\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from utils.training import train_random_forest, predict_random_forest\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "feature_file = \"./features/features.hdf5\"\n",
    "data_split_file = \"./data_split.yaml\"\n",
    "features = ['mean', 'variance', 'std', 'ptp_amp', 'skewness', 'kurtosis', 'quantile', 'pow_freq_bands', 'hurst_exp', 'decorr_time']\n",
    "model_save_path = f'./models/{datetime.now().strftime('%d-%m-%y %H-%M-%S')}.joblib'\n",
    "random_state = 42\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=-1, verbose=1, random_state=random_state, class_weight='balanced')\n",
    "\n",
    "clf = train_random_forest(clf, feature_file, features, data_split_file)\n",
    "joblib.dump(clf, model_save_path)\n",
    "\n",
    "y_true_train, y_pred_train = predict_random_forest(clf, feature_file, features, data_split_file, 'train')\n",
    "y_true_val, y_pred_val = predict_random_forest(clf, feature_file, features, data_split_file, 'val')\n",
    "print(f'Classifiction report training set \\n\\n{classification_report(y_true_train, y_pred_train, target_names=[\"Kein Artefakt\", \"Artefakt\"])}\\n\\n')\n",
    "print(f'Classifiction report validtation set \\n\\n{classification_report(y_true_val, y_pred_val, target_names=[\"Kein Artefakt\", \"Artefakt\"])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4965cc",
   "metadata": {},
   "source": [
    "Die Ergebnisse sind marginal besser im Vergleich zu dem Lauf ohne das `class_weight`. Allerdings deutet der f1-Score von 1 auf Overfitting hin. Daher sollte perspektivisch eine GridSearch durchgeführt werden, etwa auf `max_depth`, `max_features` (SB) `min_samples_leaf`, `min_samples_split` (Gemnini) durchgeführt werden."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "artifact-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
